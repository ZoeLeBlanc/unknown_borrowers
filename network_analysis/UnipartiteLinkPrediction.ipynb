{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', None)\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "# import community\n",
    "from networkx.readwrite import json_graph\n",
    "# import nx_altair as nxa\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "from pyvis import network as net\n",
    "# from node2vec import Node2Vec\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import itertools\n",
    "import collections\n",
    "from tqdm.notebook import trange, tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from bigraph.predict import pa_predict, jc_predict, cn_predict,aa_predict, katz_predict\n",
    "from bigraph.evaluation import evaluation\n",
    "from network_analysis.birankpy import BipartiteNetwork\n",
    "from network_analysis.load_datasets import get_updated_shxco_data\n",
    "from network_analysis.generate_network_metrics import *\n",
    "from network_analysis.create_networks import *\n",
    "from network_analysis.read_write_networks import * \n",
    "from network_analysis.link_prediction import * \n",
    "members_df, books_df, borrow_events, events_df = get_updated_shxco_data(get_subscription=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.read_gexf(\"./data/borrow_events_unipartite_projected_members_graph.gexf\")\n",
    "nodes_df = pd.DataFrame.from_dict(\n",
    "    dict(g.nodes(data=True)), orient='index')\n",
    "label_dict = dict(zip(nodes_df.label, nodes_df.uri))\n",
    "graph = nx.relabel_nodes(g, label_dict)\n",
    "adj = nx.adjacency_matrix(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist = pd.read_csv('./data/borrow_events_unipartite_projected_members_edgelist.csv')\n",
    "edgelist['original_source'] = edgelist['source']\n",
    "edgelist['original_target'] = edgelist['target']\n",
    "nodelist = pd.read_csv(\n",
    "    './data/borrow_events_unipartite_projected_members_nodelist.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in edgelist.iterrows():\n",
    "    row['source'] = nodelist.loc[row['original_source'] == nodelist.node_id].uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)  # make sure train-test split is consistent between notebooks\n",
    "adj_sparse = nx.to_scipy_sparse_matrix(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing...\n",
      "generating test/val sets...\n",
      "creating false test edges...\n",
      "creating false val edges...\n",
      "creating false train edges...\n",
      "final checks for disjointness...\n",
      "creating adj_train...\n",
      "Done with train-test split!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform train-test split\n",
    "adj_train, train_edges, train_edges_false, val_edges, val_edges_false, \\\n",
    "    test_edges, test_edges_false = mask_test_edges(\n",
    "        adj_sparse, test_frac=.3, val_frac=.1, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new graph object with only non-hidden edges\n",
    "g_train = nx.from_scipy_sparse_matrix(adj_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes: 528\n",
      "Total edges: 19592\n",
      "Training edges (positive): 11756\n",
      "Training edges (negative): 11756\n",
      "Validation edges (positive): 1959\n",
      "Validation edges (negative): 1959\n",
      "Test edges (positive): 5877\n",
      "Test edges (negative): 5877\n"
     ]
    }
   ],
   "source": [
    "# Inspect train/test split\n",
    "print(\"Total nodes:\", adj_sparse.shape[0])\n",
    "# adj is symmetric, so nnz (num non-zero) = 2*num_edges\n",
    "print(\"Total edges:\", int(adj_sparse.nnz/2))\n",
    "print(\"Training edges (positive):\", len(train_edges))\n",
    "print(\"Training edges (negative):\", len(train_edges_false))\n",
    "print(\"Validation edges (positive):\", len(val_edges))\n",
    "print(\"Validation edges (negative):\", len(val_edges_false))\n",
    "print(\"Test edges (positive):\", len(test_edges))\n",
    "print(\"Test edges (negative):\", len(test_edges_false))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_score(edges_pos, edges_neg, score_matrix):\n",
    "    # Store positive edge predictions, actual values\n",
    "    preds_pos = []\n",
    "    pos = []\n",
    "    for edge in edges_pos:\n",
    "        preds_pos.append(score_matrix[edge[0], edge[1]])  # predicted score\n",
    "        # actual value (1 for positive)\n",
    "        pos.append(adj_sparse[edge[0], edge[1]])\n",
    "\n",
    "    # Store negative edge predictions, actual values\n",
    "    preds_neg = []\n",
    "    neg = []\n",
    "    for edge in edges_neg:\n",
    "        preds_neg.append(score_matrix[edge[0], edge[1]])  # predicted score\n",
    "        # actual value (0 for negative)\n",
    "        neg.append(adj_sparse[edge[0], edge[1]])\n",
    "\n",
    "    # Calculate scores\n",
    "    preds_all = np.hstack([preds_pos, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds_pos)), np.zeros(len(preds_neg))])\n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "    return roc_score, ap_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Adamic-Adar indexes from g_train\n",
    "aa_matrix = np.zeros(adj.shape)\n",
    "# (u, v) = node indices, p = Adamic-Adar index\n",
    "for u, v, p in nx.adamic_adar_index(g_train):\n",
    "    aa_matrix[u][v] = p\n",
    "    aa_matrix[v][u] = p  # make sure it's symmetric\n",
    "\n",
    "# Normalize array\n",
    "aa_matrix = aa_matrix / aa_matrix.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adamic-Adar Test ROC score:  0.9307033622648676\n",
      "Adamic-Adar Test AP score:  0.9291000236718376\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROC AUC and Average Precision\n",
    "aa_roc, aa_ap = get_roc_score(test_edges, test_edges_false, aa_matrix)\n",
    "\n",
    "print('Adamic-Adar Test ROC score: ', str(aa_roc))\n",
    "print('Adamic-Adar Test AP score: ', str(aa_ap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Jaccard Coefficients from g_train\n",
    "jc_matrix = np.zeros(adj.shape)\n",
    "# (u, v) = node indices, p = Jaccard coefficient\n",
    "for u, v, p in nx.jaccard_coefficient(g_train):\n",
    "    jc_matrix[u][v] = p\n",
    "    jc_matrix[v][u] = p  # make sure it's symmetric\n",
    "\n",
    "# Normalize array\n",
    "jc_matrix = jc_matrix / jc_matrix.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Coefficient Test ROC score:  0.8878069764005919\n",
      "Jaccard Coefficient Test AP score:  0.8842410074431496\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROC AUC and Average Precision\n",
    "jc_roc, jc_ap = get_roc_score(test_edges, test_edges_false, jc_matrix)\n",
    "\n",
    "print('Jaccard Coefficient Test ROC score: ', str(jc_roc))\n",
    "print('Jaccard Coefficient Test AP score: ', str(jc_ap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate, store Adamic-Index scores in array\n",
    "pa_matrix = np.zeros(adj.shape)\n",
    "# (u, v) = node indices, p = Jaccard coefficient\n",
    "for u, v, p in nx.preferential_attachment(g_train):\n",
    "    pa_matrix[u][v] = p\n",
    "    pa_matrix[v][u] = p  # make sure it's symmetric\n",
    "\n",
    "# Normalize array\n",
    "pa_matrix = pa_matrix / pa_matrix.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preferential Attachment Test ROC score:  0.9197610861872051\n",
      "Preferential Attachment Test AP score:  0.9185476075334742\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROC AUC and Average Precision\n",
    "pa_roc, pa_ap = get_roc_score(test_edges, test_edges_false, pa_matrix)\n",
    "\n",
    "print('Preferential Attachment Test ROC score: ', str(pa_roc))\n",
    "print('Preferential Attachment Test AP score: ', str(pa_ap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_score_emb(edges_pos, edges_neg, embeddings):\n",
    "    score_matrix = np.dot(embeddings, embeddings.T)\n",
    "    \n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    # Store positive edge predictions, actual values\n",
    "    preds_pos = []\n",
    "    pos = []\n",
    "    for edge in edges_pos:\n",
    "        preds_pos.append(sigmoid(score_matrix[edge[0], edge[1]])) # predicted score\n",
    "        pos.append(adj_sparse[edge[0], edge[1]]) # actual value (1 for positive)\n",
    "        \n",
    "    # Store negative edge predictions, actual values\n",
    "    preds_neg = []\n",
    "    neg = []\n",
    "    for edge in edges_neg:\n",
    "        preds_neg.append(sigmoid(score_matrix[edge[0], edge[1]])) # predicted score\n",
    "        neg.append(adj_sparse[edge[0], edge[1]]) # actual value (0 for negative)\n",
    "        \n",
    "    # Calculate scores\n",
    "    preds_all = np.hstack([preds_pos, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds_pos)), np.zeros(len(preds_neg))])\n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "    return roc_score, ap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import spectral_embedding\n",
    "\n",
    "# Get spectral embeddings (16-dim)\n",
    "emb = spectral_embedding(adj_train, n_components=16, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Clustering Test ROC score:  0.6271955446531382\n",
      "Spectral Clustering Test AP score:  0.5419932256219776\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROC AUC and Average Precision\n",
    "sc_roc, sc_ap = get_roc_score_emb(test_edges, test_edges_false, emb)\n",
    "\n",
    "print('Spectral Clustering Test ROC score: ', str(sc_roc))\n",
    "print('Spectral Clustering Test AP score: ', str(sc_ap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import node2vec\n",
    "from gensim.models import Word2Vec\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64bc08f1a64889c0d194e5f8836772fcdd5223ec9e3efb4bcd3e9cf106aac237"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('unknown_borrowers_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
