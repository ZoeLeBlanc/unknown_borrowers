{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', None)\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "# import community\n",
    "from networkx.readwrite import json_graph\n",
    "# import nx_altair as nxa\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "from pyvis import network as net\n",
    "# from node2vec import Node2Vec\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import collections\n",
    "from tqdm.notebook import trange, tqdm\n",
    "tqdm.pandas()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from bigraph.predict import pa_predict, jc_predict, cn_predict,aa_predict\n",
    "from network_analysis.birankpy import BipartiteNetwork\n",
    "from network_analysis.load_datasets import get_updated_shxco_data\n",
    "from network_analysis.generate_network_metrics import *\n",
    "from network_analysis.create_networks import *\n",
    "from network_analysis.read_write_networks import * \n",
    "members_df, books_df, borrow_events, events_df = get_updated_shxco_data(get_subscription=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relativedelta(months=+6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "sixmonths = relativedelta(months=6)\n",
    "sixmonths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_id</th>\n",
       "      <th>subscription_start</th>\n",
       "      <th>subscription_end</th>\n",
       "      <th>known_borrows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>martin-maud</td>\n",
       "      <td>1923-10-17</td>\n",
       "      <td>1923-11-17</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     member_id subscription_start subscription_end  known_borrows\n",
       "0  martin-maud         1923-10-17       1923-11-17             36"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_events = events_df[events_df.item_uri.isna() == False].copy()\n",
    "\n",
    "partial_df = pd.read_csv('../dataset_generator/data/partial_borrowers.csv')\n",
    "partial_df[0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_members = partial_df.member_id.unique().tolist()\n",
    "# parse subscription dates so we can use them to identify circulating books\n",
    "partial_df['subscription_starttime'] = pd.to_datetime(\n",
    "    partial_df['subscription_start'], errors='coerce')\n",
    "partial_df['subscription_endtime'] = pd.to_datetime(\n",
    "    partial_df['subscription_end'], errors='coerce')\n",
    "\n",
    "events_df['start_datetime'] = pd.to_datetime(events_df['start_datetime'], errors='coerce')\n",
    "events_df['end_datetime'] = pd.to_datetime(events_df['end_datetime'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bipartite Link Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reloading saved graph: ./data/full_events_bipartite\n"
     ]
    }
   ],
   "source": [
    "member_attrs = {'uri': 'member_id'}\n",
    "book_attrs = {'uri': 'item_uri'}\n",
    "edge_attrs = {'weight': 'counts'}\n",
    "all_events_grouped = all_events.groupby(\n",
    "    ['member_id', 'item_uri']).size().reset_index(name='counts')\n",
    "\n",
    "should_process = True\n",
    "write_to_file = True\n",
    "sk_metrics = ['katz', 'louvain']\n",
    "link_metrics = ['HITS', 'CoHITS', 'BiRank', 'BGRM']\n",
    "\n",
    "\n",
    "all_events_bipartite_graph, all_events_bipartite_nodelist, all_events_bipartite_edgelist, all_events_members, all_events_books = check_reload_build_bipartite_graphs(\n",
    "    all_events_grouped, member_attrs, book_attrs, edge_attrs, should_process, write_to_file, './data/full_events_bipartite', sk_metrics, link_metrics, members_df, books_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bipartite_link_predictions(graph):\n",
    "    print('Running jaccard link prediction')\n",
    "    jc_preds = jc_predict(graph)\n",
    "    jc_preds_df = pd.DataFrame(data=list(jc_preds.values()),index=jc_preds.keys()).reset_index()\n",
    "    jc_preds_df.columns = ['member_id', 'item_uri', 'jc_prediction']\n",
    "    print('Running preferential attachment link prediction')\n",
    "    pa_preds = pa_predict(graph)\n",
    "    pa_preds_df = pd.DataFrame(data=list(pa_preds.values()),index=pa_preds.keys()).reset_index()\n",
    "    pa_preds_df.columns = ['member_id', 'item_uri', 'pa_prediction']\n",
    "    print('Running common neighbors link prediction')\n",
    "    cn_preds = cn_predict(graph)\n",
    "    cn_preds_df = pd.DataFrame(\n",
    "        data=list(cn_preds.values()), index=cn_preds.keys()).reset_index()\n",
    "    cn_preds_df.columns = ['member_id', 'item_uri', 'cn_prediction']\n",
    "    print('Running adamic adar link prediction')\n",
    "    aa_preds = aa_predict(graph)\n",
    "    aa_preds_df = pd.DataFrame(\n",
    "        data=list(aa_preds.values()), index=aa_preds.keys()).reset_index()\n",
    "    aa_preds_df.columns = ['member_id', 'item_uri', 'aa_prediction']\n",
    "\n",
    "\n",
    "    all_preds = pd.merge(jc_preds_df, pa_preds_df, on=['member_id', 'item_uri'], how='outer')\n",
    "    all_preds = pd.merge(all_preds, cn_preds_df, on=['member_id', 'item_uri'], how='outer')\n",
    "    all_preds = pd.merge(all_preds, aa_preds_df, on=['member_id', 'item_uri'], how='outer')\n",
    "    return all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jaccard link prediction\n",
      "Jaccard Executed in 53.186678886413574 seconds \n",
      "\n",
      "Running preferential attachment link prediction\n",
      "Preferential attachment Executed in 38.66534900665283 seconds \n",
      "\n",
      "Running common neighbors link prediction\n",
      "Common neighbours Executed in 32.77828574180603 seconds \n",
      "\n",
      "Running adamic adar link prediction\n",
      "Adamic_adar prediction starting...\n",
      "Adamic-adar Executed in 125.47807121276855 seconds \n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_preds = get_bipartite_link_predictions(all_events_bipartite_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jc_prediction</th>\n",
       "      <th>pa_prediction</th>\n",
       "      <th>cn_prediction</th>\n",
       "      <th>aa_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jc_prediction</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018728</td>\n",
       "      <td>0.352680</td>\n",
       "      <td>0.312518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pa_prediction</th>\n",
       "      <td>-0.018728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.531993</td>\n",
       "      <td>0.559736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cn_prediction</th>\n",
       "      <td>0.352680</td>\n",
       "      <td>0.531993</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa_prediction</th>\n",
       "      <td>0.312518</td>\n",
       "      <td>0.559736</td>\n",
       "      <td>0.981303</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               jc_prediction  pa_prediction  cn_prediction  aa_prediction\n",
       "jc_prediction       1.000000      -0.018728       0.352680       0.312518\n",
       "pa_prediction      -0.018728       1.000000       0.531993       0.559736\n",
       "cn_prediction       0.352680       0.531993       1.000000       0.981303\n",
       "aa_prediction       0.312518       0.559736       0.981303       1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds[['jc_prediction', 'pa_prediction',\n",
    "           'cn_prediction', 'aa_prediction']].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_lookup = {row.uri: row.title for row in books_df.itertuples()}\n",
    "metrics = ['jc_prediction', 'pa_prediction',\n",
    "           'cn_prediction', 'aa_prediction']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "dfs =[ ]\n",
    "def generate_top_predictions_for_table(row, metrics, number_of_results, predictions_df, limit_to_circulation=True):\n",
    "    identified_top_predictions = {}\n",
    "    circulation_start = row.subscription_starttime - sixmonths\n",
    "    circulation_events = events_df[events_df.start_datetime.between(circulation_start, row.subscription_endtime) | events_df.end_datetime.between(circulation_start, row.subscription_endtime)]\n",
    "    popular_current = circulation_events.groupby(['item_uri']).size().reset_index(name='Count').sort_values(['Count'], ascending=False)[0:number_of_results].item_uri.tolist()\n",
    "    identified_top_predictions['popular_current'] = popular_current\n",
    "    for idx, m in enumerate(metrics):\n",
    "        subset_predictions = get_predictions_by_metric(row, m, predictions_df, limit_to_circulation)\n",
    "        identified_top_predictions[m] = subset_predictions[0:number_of_results].item_uri.tolist()\n",
    "    \n",
    "    df_final = pd.DataFrame.from_dict(identified_top_predictions, orient='columns')\n",
    "    df_final['member_id'] = row.member_id\n",
    "    df_final['subscription_starttime'] = row.subscription_starttime\n",
    "    df_final['subscription_endtime'] = row.subscription_endtime\n",
    "    print(type(df_final))\n",
    "    return df_final\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_by_metric(row, metric, predictions_df, circulation_books, limit_to_circulation=True):\n",
    "    if limit_to_circulation:\n",
    "        subset_predictions = predictions_df[(predictions_df.member_id == row.member_id) & (\n",
    "            predictions_df.item_uri.isin(circulation_books))].sort_values(by=f'{metric}', ascending=False)\n",
    "    else:\n",
    "        subset_predictions = predictions_df[(\n",
    "            predictions_df.member_id == row.member_id)].sort_values(by=f'{metric}', ascending=False)\n",
    "\n",
    "    return subset_predictions[['member_id', 'item_uri', f'{metric}']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1304db7e16ad4f4da1c6f85997461681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/219 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "number_of_results = 10\n",
    "limit_to_circulation = True\n",
    "predictions_df = all_preds.copy()\n",
    "dfs = []\n",
    "for index, row in tqdm(partial_df.iterrows(), total=partial_df.shape[0]):\n",
    "    identified_top_predictions = {}\n",
    "    circulation_start = row.subscription_starttime - sixmonths\n",
    "    circulation_events = events_df[events_df.start_datetime.between(\n",
    "        circulation_start, row.subscription_endtime) | events_df.end_datetime.between(circulation_start, row.subscription_endtime)]\n",
    "    popular_current = circulation_events.groupby(['item_uri']).size().reset_index(\n",
    "        name='counts').sort_values(['counts'], ascending=False)[0:number_of_results]\n",
    "    circulation_books = circulation_events.item_uri.unique().tolist()\n",
    "    identified_top_predictions['popular_current_books'] = popular_current.item_uri.tolist(\n",
    "    )\n",
    "    identified_top_predictions['popular_current_counts'] = popular_current.counts.tolist(\n",
    "    )\n",
    "    for idx, m in enumerate(metrics):\n",
    "        subset_predictions = get_predictions_by_metric(\n",
    "            row, m, predictions_df, circulation_books, limit_to_circulation)\n",
    "        identified_top_predictions[m] = subset_predictions[0:number_of_results].item_uri.tolist()\n",
    "        identified_top_predictions[f'{m}_scores'] = subset_predictions[0:number_of_results][m].tolist(\n",
    "        )\n",
    "\n",
    "    df_final = pd.DataFrame.from_dict(\n",
    "        identified_top_predictions, orient='columns')\n",
    "\n",
    "    df_final['member_id'] = row.member_id\n",
    "    df_final['subscription_starttime'] = row.subscription_starttime\n",
    "    df_final['subscription_endtime'] = row.subscription_endtime\n",
    "    df_final['known_borrows'] = row.known_borrows\n",
    "\n",
    "    output_path = './data/partial_bipartite_link_predictions.csv'\n",
    "    if index == 0:\n",
    "        os.remove(output_path)\n",
    "    if os.path.exists(output_path):\n",
    "        df_final.to_csv(output_path, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df_final.to_csv(output_path, index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JaccardIndex()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples = [tuple(x) for x in all_events_bipartite_edgelist.values]\n",
    "graph = convert_edge_list(tuples, bipartite=True)\n",
    "biadjacency = graph.biadjacency\n",
    "names = graph.names\n",
    "ji = JaccardIndex()\n",
    "ji.fit(biadjacency)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most similar members based on book history ['martin-maud' 'rolland-madeleine' 'martin-simone' 'wilson-romer'\n",
      " 'rice-matilda' 'valerio' 'pottecher-therese' 'foret' 'somerville' 'savy']\n",
      "most similar members based on book history ['reynolds-a-m' 'bernheim' 'ottocar' 'ris' 'james-t-m' 'lacroix-e'\n",
      " 'potocki-de-montalk' 'antoine-may' 'sperry' 'monnier-j']\n",
      "most similar members based on book history ['linossier-raymonde' 'sarraute' 'antoine-may' 'pfeffel' 'ottensooser'\n",
      " 'oerthel' 'joyce-lucia' 'suter' 'reverchon' 'violette']\n",
      "most similar members based on book history ['mcgrew-marie-carroll' 'edwards-thomas' 'ybarra-penny' 'bremond'\n",
      " 'camerlynck-guernier' 'faulkner-norma' 'killen' 'raphael-france'\n",
      " 'antoine-may' 'mespoulet']\n",
      "most similar members based on book history ['richard-p' 'lucas-b' 'dyer-louise' 'venable' 'walker-natalie' 'imbs'\n",
      " 'suter' 'lambert-jacqueline' 'gerbault-paul' 'edwards-thomas']\n",
      "most similar members based on book history ['mcalmon-robert' 'samyn' 'lanux-pierre-de' 'metcalf-thomas-n'\n",
      " 'crane-louise' 'harden-e' 'chareau-dorothee' 'wegner' 'brooks-alden'\n",
      " 'pagan']\n",
      "most similar members based on book history ['jolas-maria' 'metcalf-thomas-n' 'saillet' 'weiss-colette' 'gascoyne'\n",
      " 'potocki-de-montalk' 'harden-e' 'chareau-dorothee' 'alvear'\n",
      " 'mcalmon-robert']\n",
      "most similar members based on book history ['kittredge-eleanor-hayden' 'claudius' 'church-henry' 'waterfield-gordon'\n",
      " 'waterfield' 'killen' 'marcilly' 'massey' 'colens' 'mackenzie-d-s-s']\n",
      "most similar members based on book history ['waterfield-gordon' 'kittredge-eleanor-hayden' 'teissier-jeanine-delpech'\n",
      " 'church-henry' 'couet' 'bernheim-francoise' 'waterfield' 'pouree'\n",
      " 'mackenzie-d-s-s' 'pringle-lady']\n",
      "most similar members based on book history ['putzel' 'pressly' 'lamberts' 'duhamel-marcel' 'reid-john' 'camp'\n",
      " 'alderman' 'church-barbara' 'harden-e' 'paul-elliot-2']\n",
      "most similar members based on book history ['theves' 'culley' 'vigan' 'tony-mayer' 'thellier-de-poncheville'\n",
      " 'guillemin' 'bouniols-louise-olga' 'venable' 'clizbe'\n",
      " 'bernheim-francoise']\n",
      "most similar members based on book history ['sarraute' 'oerthel' 'pottier-ph' 'pfeffel' 'gischia-leon'\n",
      " 'linossier-raymonde' 'clark-john-darcy' 'ralli' 'hebant' 'violette']\n",
      "most similar members based on book history ['thellier-de-poncheville' 'busy' 'forest-divonne' 'theves'\n",
      " 'gerbault-paul' 'mespoulet' 'shelley-dorothy' 'vigan'\n",
      " 'bernheim-antoinette' 'bazin-de-jessey']\n",
      "most similar members based on book history ['hemingway' 'murray-john-3' 'le-gallienne-richard' 'jackson-5' 'yarrow'\n",
      " 'mcalmon-robert' 'campbell-arlen' 'weaver-audrey' 'stirling-monica'\n",
      " 'sheldon-james-s']\n",
      "most similar members based on book history ['philip' 'melik' 'service' 'michaelides-l' 'varney' 'martin-maud'\n",
      " 'bourdet' 'pfeiffer-pauline' 'metcalf-thomas-n' 'wilder-charlotte']\n",
      "most similar members based on book history ['poirson' 'lambert-jacqueline' 'fitzgerald' 'grassot' 'hebant'\n",
      " 'thellier-de-poncheville' 'culley' 'yarrow' 'theves' 'davaine']\n",
      "most similar members based on book history ['price-phyllis' 'citron-pierre' 'plummer' 'pagan' 'massey' 'prenter'\n",
      " 'vigan' 'colens' 'rirachowsky' 'bernheim-antoinette']\n",
      "most similar members based on book history ['rolland-madeleine' 'valerio' 'pagan' 'violette' 'renoir' 'ottensooser'\n",
      " 'martin-maud' 'ottocar' 'guillemin' 'wendel']\n",
      "most similar members based on book history ['morgan' 'killen' 'waterfield' 'marcilly' 'mackenzie-d-s-s'\n",
      " 'teissier-jeanine-delpech' 'pouree' 'kittredge-eleanor-hayden'\n",
      " 'raphael-france' 'church-barbara']\n",
      "most similar members based on book history ['robertson-william-cowper' 'dolan' 'dupre-marie-antoinette'\n",
      " 'meyer-florence' 'montricher-cecile-de' 'lecoeur' 'wood-thelma' 'sperry'\n",
      " 'whitman-tania' 'marsland']\n",
      "most similar members based on book history ['culver-donald' 'bonnerot' 'bernheim-antoinette' 'porter-katherine-anne'\n",
      " 'citron-pierre' 'kittredge-eleanor-hayden' 'colens' 'rivoallan-anatole'\n",
      " 'tony-mayer' 'wendel']\n",
      "most similar members based on book history ['colens' 'marcilly' 'raphael-france' 'kittredge-eleanor-hayden'\n",
      " 'claudius' 'vigan' 'rirachowsky' 'church-henry' 'killen'\n",
      " 'shelley-dorothy']\n",
      "most similar members based on book history ['delimal-eric' 'tehin' 'forest-divonne' 'vienne' 'massuger' 'chalot'\n",
      " 'pagan' 'bidoire-boulenger' 'jackson-5' 'porcher']\n",
      "most similar members based on book history ['lafleur' 'ybarra-penny' 'francs' 'theves' 'thellier-de-poncheville'\n",
      " 'mcgrew-marie-carroll' 'raphael-france' 'killen' 'alderman' 'ramniklalk']\n",
      "most similar members based on book history ['alexandre' 'bloch-marguerite-herzog' 'maurois' 'potocki-de-montalk'\n",
      " 'lamblin' 'solano' 'gillie' 'citron-pierre' 'bernheim-francoise'\n",
      " 'montricher-cecile-de']\n",
      "most similar members based on book history ['nguyen-minh-truyel' 'alderman' 'raousset' 'raphael-france' 'reavely'\n",
      " 'reeves' 'regnier' 'reid-john' 'reid-marjorie' 'renaudin']\n",
      "most similar members based on book history ['gros-2' 'raousset' 'raphael-france' 'reavely' 'reeves' 'regnier'\n",
      " 'reid-john' 'reid-marjorie' 'alderman' 'renaudin']\n",
      "most similar members based on book history ['campbell-arlen' 'shapiro-phyllis-w' 'beauvoir-simone-de' 'culbert'\n",
      " 'tony-mayer' 'baker-3' 'bazin-de-jessey' 'teissier-jeanine-delpech'\n",
      " 'harden-e' 'catel-jean']\n",
      "most similar members based on book history ['bernheim-francoise' 'bernheim-antoinette' 'wissotzky' 'killen'\n",
      " 'marcilly' 'rirachowsky' 'tony-mayer' 'kittredge-eleanor-hayden'\n",
      " 'boscq-marie' 'vigan']\n",
      "most similar members based on book history ['harvey-dorothy-dudley' 'wolkowitsch' 'focillon-marguerite'\n",
      " 'gischia-gerry' 'leibowitz' 'wood-thelma' 'devies' 'fitzgerald' 'lamblin'\n",
      " 'beauvoir-simone-de']\n",
      "most similar members based on book history ['raphael-france' 'killen' 'colens' 'shelley-dorothy'\n",
      " 'kittredge-eleanor-hayden' 'bremond' 'burt-maud' 'marcilly' 'vigan'\n",
      " 'ottocar']\n",
      "most similar members based on book history ['wilson-natalie' 'service' 'colens' 'reynal' 'ralli' 'ramniklalk'\n",
      " 'raousset' 'raphael-france' 'reavely' 'reeves']\n",
      "most similar members based on book history ['weiss-colette' 'tree' 'jolas-maria' 'rogers-samuel' 'harden-e' 'saillet'\n",
      " 'metcalf-thomas-n' 'coche-de-la-ferte' 'flandrau' 'alvear']\n",
      "most similar members based on book history ['yeats-anne' 'engelman' 'wegner' 'brooks-alden' 'rodman' 'denoel-jean'\n",
      " 'wolkowitsch' 'wright-richard' 'cayton' 'metcalf-thomas-n']\n",
      "most similar members based on book history ['lamy-marthe' 'jeanneney-marie-laure-monod' 'dalsace' 'busy' 'knipper'\n",
      " 'forest-divonne' 'chalot' 'davaine' 'gerbault-paul' 'wolkowitsch']\n",
      "most similar members based on book history ['sheldon-james-s' 'bremond' 'shelley-dorothy' 'le-gallienne-richard'\n",
      " 'lamblin' 'raphael-france' 'lacroix-e' 'schirmer' 'stein-leo' 'pagan']\n",
      "most similar members based on book history ['bishop-elizabeth' 'alderman' 'raousset' 'raphael-france' 'reavely'\n",
      " 'reeves' 'regnier' 'reid-john' 'reid-marjorie' 'renaudin']\n",
      "most similar members based on book history ['reid-marjorie' 'aragon' 'porel' 'ullmann-lisette' 'rodker' 'cazes'\n",
      " 'trevelyan-julian' 'clairin-pierre-eugene' 'coche-de-la-ferte'\n",
      " 'scudder-thomas']\n",
      "most similar members based on book history ['rodker' 'prevost-jean' 'reid-marjorie' 'aragon' 'porel'\n",
      " 'ullmann-lisette' 'cazes' 'trevelyan-julian' 'clairin-pierre-eugene'\n",
      " 'coche-de-la-ferte']\n",
      "most similar members based on book history ['wilder-thornton' 'boyd-james' 'rice-matilda' 'sweeney-james'\n",
      " 'riviere-jean' 'melot' 'wilson-romer' 'varney' 'masse' 'rolo']\n",
      "most similar members based on book history ['summerell' 'sachs' 'rhys' 'swan' 'sykes-christopher' 'joyce-lucia'\n",
      " 'lecoeur' 'monnier-j' 'somerville' 'ottensooser']\n",
      "most similar members based on book history ['service' 'varney' 'philip' 'faidherbe' 'loon' 'martin-maud'\n",
      " 'wilson-natalie' 'dupre-marie-antoinette' 'orbison-douglas'\n",
      " 'picard-pierre']\n",
      "most similar members based on book history ['sargent' 'ralli' 'pottecher-therese' 'vechten' 'rieder' 'schlumberger'\n",
      " 'martin-maud' 'raousset' 'schereck' 'ottocar']\n",
      "most similar members based on book history ['richardson-marian' 'valerio' 'alderman' 'ramniklalk' 'raousset'\n",
      " 'raphael-france' 'reavely' 'reeves' 'regnier' 'reid-john']\n",
      "most similar members based on book history ['rivoallan-anatole' 'paul-dubois' 'shelley-dorothy' 'valerio'\n",
      " 'bernheim-antoinette' 'rieder' 'pagan' 'violette' 'rirachowsky'\n",
      " 'citron-pierre']\n",
      "most similar members based on book history ['bernheim' 'ottocar' 'reynolds-a-m' 'gerbault-paul' 'lacroix-e'\n",
      " 'raphael-france' 'prot' 'fournier-jeanne' 'montricher-cecile-de' 'wigram']\n",
      "most similar members based on book history ['flanner' 'beaulieu' 'lacorne' 'pfeffel' 'clogenson' 'chaudot'\n",
      " 'murphy-dudley' 'walker-natalie' 'clark-john-darcy' 'grassot']\n",
      "most similar members based on book history ['du-bos' 'lambert-jacqueline' 'bourdet' 'dalsace' 'oppen'\n",
      " 'metcalf-thomas-n' 'garano-gonzalez' 'reavely' 'dennis-holly' 'moal-le']\n",
      "most similar members based on book history ['shaw-m-r-b' 'savy' 'wilde-dorothy' 'alderman' 'raousset'\n",
      " 'raphael-france' 'reavely' 'reeves' 'regnier' 'reid-john']\n",
      "most similar members based on book history ['thayer-woodbridge' 'schirmer' 'gischia-leon' 'varney' 'solano' 'wibbelz'\n",
      " 'lacroix-e' 'murray-john-3' 'le-gallienne-richard' 'stein-leo']\n",
      "most similar members based on book history ['reavely' 'cazes' 'trevelyan-julian' 'tery' 'scudder-raymond' 'schenk'\n",
      " 'ralli' 'aragon' 'torrence' 'reid-marjorie']\n",
      "most similar members based on book history ['imbs' 'yarrow' 'le-gallienne-richard' 'vigan' 'pottier-ph' 'guillemin'\n",
      " 'stevens-george' 'clark-john-darcy' 'hebant' 'sarraute']\n",
      "most similar members based on book history ['williams-marjorie' 'weaver-audrey' 'watson-capt' 'pfeiffer-virginia'\n",
      " 'pottecher-therese' 'dherbais-de-thun' 'espitalier' 'clizbe'\n",
      " 'bidoire-boulenger' 'proix']\n",
      "most similar members based on book history ['smyth-pigott' 'king-f' 'speaight-r-l' 'wigram' 'bernheim' 'schirmer'\n",
      " 'vogue-de' 'fournier-jeanne' 'wyck' 'murray-john-3']\n",
      "most similar members based on book history ['montricher-cecile-de' 'shelley-dorothy' 'pagan' 'bremond' 'lecoeur'\n",
      " 'vogein' 'potocki-de-montalk' 'rirachowsky' 'delimal' 'fournier-jeanne']\n",
      "most similar members based on book history ['richardson-mrs-arthur' 'speaight-r-l' 'rocatallada' 'franchot'\n",
      " 'rowe-dutton' 'cassaigne' 'plummer' 'citron-pierre'\n",
      " 'montricher-cecile-de' 'lacroix-e']\n",
      "most similar members based on book history ['aldington-richard' 'lacroix-e' 'colens' 'raphael-france' 'alderman'\n",
      " 'raousset' 'reavely' 'reeves' 'regnier' 'reid-john']\n",
      "most similar members based on book history ['eloff-fanie' 'harmsworth-desmond' 'perkins' 'king-f' 'dyer-louise'\n",
      " 'schlumberger-jean' 'wallace-lillian' 'upton' 'desclos-anne' 'lecoeur']\n",
      "most similar members based on book history ['sperry' 'proix' 'dolan' 'vienne' 'montricher-cecile-de' 'joyce-giorgio'\n",
      " 'jackson-5' 'parrain' 'edwards-thomas' 'sheldon-james-s']\n",
      "most similar members based on book history ['lewisohn' 'goldman-emma' 'puy-fontaine' 'grassot' 'devies'\n",
      " 'kennedy-robert' 'child-bertha-cushing' 'faulkner-norma' 'prenter'\n",
      " 'paul-dubois']\n",
      "most similar members based on book history ['boscq-marie' 'shelley-dorothy' 'lamblin' 'guillemin' 'citron-pierre'\n",
      " 'gischia-leon' 'tony-mayer' 'bernheim-francoise' 'vigan' 'culley']\n",
      "most similar members based on book history ['gillet-louis' 'gascoyne' 'dillon' 'exideuil' 'melik' 'bourdet'\n",
      " 'pfeiffer-pauline' 'wang-chun-jen' 'mantoy' 'marotte']\n",
      "most similar members based on book history ['paul-dubois' 'rivoallan-anatole' 'mercanton' 'mazon' 'proix'\n",
      " 'bernheim-antoinette' 'puy-fontaine' 'joyce-james' 'morrow'\n",
      " 'michaelides-l']\n",
      "most similar members based on book history ['frieseke-sarah-anne' 'wickham' 'roberts-3' 'stirling-monica' 'stein-leo'\n",
      " 'kittredge-eleanor-hayden' 'alderman' 'raphael-france' 'reavely' 'reeves']\n",
      "most similar members based on book history ['denis-graterolle' 'merrick-leonard' 'prenter' 'lecoeur' 'lyon-martine'\n",
      " 'tuttle-stephen-d' 'mercanton' 'wendel' 'lord-eda' 'delimal']\n",
      "most similar members based on book history ['connolly-cyril' 'dennis-holly' 'perkins' 'milward-j-d' 'martinuzzi'\n",
      " 'pasquier-jean' 'satenstein' 'bloch-marguerite-herzog' 'levinson-marie'\n",
      " 'martin-simone']\n",
      "most similar members based on book history ['dherbais-de-thun' 'aragon' 'reid-marjorie' 'porel' 'guiringaud'\n",
      " 'ullmann-lisette' 'rodker' 'cazes' 'trevelyan-julian' 'churchill']\n",
      "most similar members based on book history ['burt-maud' 'waterfield' 'mespoulet' 'teissier-jeanine-delpech'\n",
      " 'kittredge-eleanor-hayden' 'marcilly' 'raphael-france'\n",
      " 'thellier-de-poncheville' 'massey' 'price-phyllis']\n",
      "most similar members based on book history ['duteurtre' 'solano' 'joyce-giorgio' 'edwards-thomas' 'raphael-france'\n",
      " 'reavely' 'reeves' 'regnier' 'reid-john' 'reid-marjorie']\n",
      "most similar members based on book history ['francillon' 'gilbert-stuart' 'genet-mme' 'valery-francois' 'tony-mayer'\n",
      " 'church-henry' 'colens' 'alderman' 'raousset' 'raphael-france']\n",
      "most similar members based on book history ['harmsworth-desmond' 'eloff-fanie' 'worthing-13' 'sperry' 'seager'\n",
      " 'weaver-audrey' 'jackson-5' 'colens' 'raphael-france' 'killen']\n",
      "most similar members based on book history ['gide-andre' 'perkins' 'delimal' 'blaess' 'morgan' 'raphael-france'\n",
      " 'reavely' 'reeves' 'regnier' 'reid-john']\n",
      "most similar members based on book history ['heurgon-jacques' 'renaudin' 'leer' 'genet-mme' 'alvear'\n",
      " 'dennis-mary-cable' 'culley' 'gillie' 'venable' 'valery-francois']\n",
      "most similar members based on book history ['genet-mme' 'goodwin-3' 'winner-harry-e' 'francillon' 'rogers-samuel'\n",
      " 'heurgon-jacques' 'swan' 'sykes-christopher' 'dudley' 'waller-robert']\n",
      "most similar members based on book history ['goodwin-3' 'genet-mme' 'raphael-france' 'reavely' 'reeves' 'regnier'\n",
      " 'reid-john' 'reid-marjorie' 'renaudin' 'renoir']\n",
      "most similar members based on book history ['swasey' 'tuttle-stephen-d' 'potocki-de-montalk' 'fombeure' 'guilloux'\n",
      " 'wolkowitsch' 'pasquier-jean' 'maxwell' 'saillet' 'oppen']\n",
      "most similar members based on book history ['royer-sement' 'lamont' 'grassot' 'brinquant-simone'\n",
      " 'baldwin-helen-green' 'menzies' 'farrar' 'rowe-dutton' 'ybarra-penny'\n",
      " 'mercanton']\n",
      "most similar members based on book history ['gerbault-paul' 'forest-divonne' 'clairin-theresa' 'lamy-marthe' 'chalot'\n",
      " 'busy' 'davaine' 'thellier-de-poncheville' 'delimal' 'monnier-j']\n",
      "most similar members based on book history ['bouniols-louise-olga' 'prochasson' 'culley' 'guillemin' 'dalsace'\n",
      " 'lamy-marthe' 'faulkner-norma' 'theves' 'clizbe' 'watson-capt']\n",
      "most similar members based on book history ['grassot' 'spira' 'lewisohn' 'goldman-emma' 'puy-fontaine' 'marotte'\n",
      " 'brull' 'laporte' 'lubersac' 'poirson']\n",
      "most similar members based on book history ['marcel-gabriel' 'savitsky' 'denis-graterolle' 'montricher-cecile-de'\n",
      " 'kittredge-eleanor-hayden' 'colens' 'alderman' 'reavely' 'reeves'\n",
      " 'regnier']\n",
      "most similar members based on book history ['vienne' 'martinuzzi' 'vandel' 'lubersac' 'delimal-eric' 'gischia-gerry'\n",
      " 'lafoy' 'van-den-bergh' 'parrain' 'devies']\n",
      "most similar members based on book history ['forest-divonne' 'gerbault-paul' 'chalot' 'knipper'\n",
      " 'jeanneney-marie-laure-monod' 'lamy-marthe' 'clairin-theresa'\n",
      " 'prevost-gerard' 'thellier-de-poncheville' 'monnier-j']\n",
      "most similar members based on book history ['merzbach' 'sachs' 'lebois' 'wilson-margaret' 'tery' 'coche-de-la-ferte'\n",
      " 'hommel' 'savitsky' 'vieillard' 'jeanneney-marie-laure-monod']\n",
      "most similar members based on book history ['duren' 'sortor' 'lubersac' 'couet' 'elfvik' 'roditi-edouard'\n",
      " 'duff-donald' 'chopard-2' 'massuger' 'busy']\n",
      "most similar members based on book history ['shapiro-phyllis-w' 'culbert' 'alderman' 'baker-3' 'campbell-arlen'\n",
      " 'church-barbara' 'chopard-2' 'teissier-jeanine-delpech' 'waterfield'\n",
      " 'roussel-3']\n",
      "most similar members based on book history ['catel-jean' 'boyd-madeleine' 'laughlin-james'\n",
      " 'carroll-akrata-von-schrader' 'couet' 'campbell-arlen'\n",
      " 'beauvoir-simone-de' 'chopard-2' 'dupuy' 'steegmuller-francis']\n",
      "most similar members based on book history ['caetani' 'peggram' 'prenter' 'culme-seymour' 'campbell-arlen' 'bonnerot'\n",
      " 'crane-louise' 'citron-pierre' 'stirling-monica' 'baker-3']\n",
      "most similar members based on book history ['beaulieu' 'pfeffel' 'chaudot' 'clark-john-darcy' 'flanner' 'hebant'\n",
      " 'foret' 'massuger' 'pottier-ph' 'dupuy']\n",
      "most similar members based on book history ['vandel' 'wauquier' 'valery-francois' 'van-den-bergh' 'vienne' 'lafoy'\n",
      " 'levy-catherine' 'speaight-r-l' 'delimal' 'vieillard']\n",
      "most similar members based on book history ['quennell' 'coche-de-la-ferte' 'culme-seymour' 'caetani' 'bonnerot'\n",
      " 'oldenburger' 'arvanon' 'stirling-monica' 'tony-mayer'\n",
      " 'teissier-jeanine-delpech']\n",
      "most similar members based on book history ['brull' 'lubersac' 'grassot' 'spira' 'miller-10' 'hebant' 'monnier-j'\n",
      " 'yard' 'peggram' 'vienne']\n",
      "most similar members based on book history ['lestocquoy' 'raousset' 'raphael-france' 'reavely' 'reeves' 'regnier'\n",
      " 'reid-john' 'reid-marjorie' 'renaudin' 'renoir']\n"
     ]
    }
   ],
   "source": [
    "from numpy import argsort\n",
    "for member in partial_members:\n",
    "    i, = np.where(names == member)\n",
    "\n",
    "    ji_scores = ji.predict(i[0])\n",
    "\n",
    "    # col_name = '_'.join(list(pred_edge.keys()))\n",
    "    print('most similar members based on book history', names[argsort(-ji_scores)][0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unipartite Link Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reloading saved graph: ./data/all_events_unipartite_projected\n"
     ]
    }
   ],
   "source": [
    "member_attrs = {'uri': 'member_id'}\n",
    "book_attrs = {'uri': 'item_uri'}\n",
    "edge_attrs = {'weight': 'counts'}\n",
    "node_attrs = {}\n",
    "should_process = True\n",
    "write_to_file = True\n",
    "sk_metrics = ['katz', 'louvain']\n",
    "link_metrics = ['pagerank', 'hubs', 'auth']\n",
    "is_projected = True\n",
    "all_events_grouped = all_events.groupby(\n",
    "    ['member_id', 'item_uri']).size().reset_index(name='counts')\n",
    "\n",
    "\n",
    "projected_members_graph, projected_members_nodelist, projected_members_edgelist, projected_members, projected_books_graph, projected_books_nodelist, projected_books_edgelist, projected_books = check_reload_build_unipartite_graphs(\n",
    "    all_events_grouped, all_events, member_attrs, book_attrs, edge_attrs, node_attrs, should_process, write_to_file, './data/all_events_unipartite_projected', sk_metrics, link_metrics, members_df, books_df, is_projected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_link_predictions(graph, nodelist):\n",
    "    # nodelist, edgelist = generate_dataframes(graph, False, True)\n",
    "    jaccard_coefs = list(nx.jaccard_coefficient(graph))\n",
    "    jaccard_df = pd.DataFrame(jaccard_coefs, columns=['source', 'target', 'jaccard_coef_prediction'])\n",
    "    jaccard_df['updated_source'] = jaccard_df['source'].progress_apply(lambda x: nodelist[nodelist.label == x].uri.values[0])\n",
    "    jaccard_df['updated_target'] = jaccard_df['target'].progress_apply(\n",
    "        lambda x: nodelist[nodelist.label == x].uri.values[0])\n",
    "\n",
    "\n",
    "    pref_attach = nx.preferential_attachment(projected_members_graph)\n",
    "    pref_attach_df = pd.DataFrame(list(pref_attach), columns=['source', 'target', 'preferential_attachment_prediction'])\n",
    "    pref_attach_df['updated_source'] = pref_attach_df['source'].progress_apply(lambda x: nodelist[nodelist.label == x].uri.values[0])\n",
    "    pref_attach_df['updated_target'] = pref_attach_df['target'].progress_apply(\n",
    "        lambda x: nodelist[nodelist.label == x].uri.values[0])\n",
    "\n",
    "    pred_edges = pd.merge(jaccard_df, pref_attach_df, on=['updated_source', 'updated_target', 'source', 'target'])\n",
    "    return pred_edges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodelist ,edgelist = generate_dataframes(projected_members_graph, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b4aeeec77e439981ba2eb99b50c8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c027235b9e6e4d65a58969f654bfd54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0386ce93e9574633a5c4f3d850a4a74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6064e0a14d34e3e93d2f54ec577a11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_edges = get_link_predictions(\n",
    "    projected_members_graph, nodelist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>jaccard_coef_prediction</th>\n",
       "      <th>updated_source</th>\n",
       "      <th>updated_target</th>\n",
       "      <th>preferential_attachment_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50785</th>\n",
       "      <td>n611</td>\n",
       "      <td>n228</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>wright-julia</td>\n",
       "      <td>jordan-howard</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73614</th>\n",
       "      <td>n31</td>\n",
       "      <td>n186</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>bourassin-2</td>\n",
       "      <td>giedion-welcker</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59210</th>\n",
       "      <td>n197</td>\n",
       "      <td>n521</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>goyert</td>\n",
       "      <td>tabouis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83805</th>\n",
       "      <td>n448</td>\n",
       "      <td>n232</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>roger-roubin</td>\n",
       "      <td>joyce-stanislaus</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98379</th>\n",
       "      <td>n600</td>\n",
       "      <td>n42</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>wilson-natalie</td>\n",
       "      <td>bruno-jean</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169162</th>\n",
       "      <td>n134</td>\n",
       "      <td>n552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>eastman</td>\n",
       "      <td>varney</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169163</th>\n",
       "      <td>n134</td>\n",
       "      <td>n469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>eastman</td>\n",
       "      <td>saur</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169164</th>\n",
       "      <td>n134</td>\n",
       "      <td>n524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>eastman</td>\n",
       "      <td>teissier-jeanine-delpech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169165</th>\n",
       "      <td>n134</td>\n",
       "      <td>n351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>eastman</td>\n",
       "      <td>oldenburger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169166</th>\n",
       "      <td>n134</td>\n",
       "      <td>n300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>eastman</td>\n",
       "      <td>marsland</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169282 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       source target  jaccard_coef_prediction  updated_source  \\\n",
       "50785    n611   n228                 0.666667    wright-julia   \n",
       "73614     n31   n186                 0.500000     bourassin-2   \n",
       "59210    n197   n521                 0.500000          goyert   \n",
       "83805    n448   n232                 0.500000    roger-roubin   \n",
       "98379    n600    n42                 0.500000  wilson-natalie   \n",
       "...       ...    ...                      ...             ...   \n",
       "169162   n134   n552                 0.000000         eastman   \n",
       "169163   n134   n469                 0.000000         eastman   \n",
       "169164   n134   n524                 0.000000         eastman   \n",
       "169165   n134   n351                 0.000000         eastman   \n",
       "169166   n134   n300                 0.000000         eastman   \n",
       "\n",
       "                  updated_target  preferential_attachment_prediction  \n",
       "50785              jordan-howard                                   6  \n",
       "73614            giedion-welcker                                   9  \n",
       "59210                    tabouis                                   2  \n",
       "83805           joyce-stanislaus                                   2  \n",
       "98379                 bruno-jean                                   2  \n",
       "...                          ...                                 ...  \n",
       "169162                    varney                                   0  \n",
       "169163                      saur                                   0  \n",
       "169164  teissier-jeanine-delpech                                   0  \n",
       "169165               oldenburger                                   0  \n",
       "169166                  marsland                                   0  \n",
       "\n",
       "[169282 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_edges.sort_values(by=['jaccard_coef_prediction',\n",
    "                       'preferential_attachment_prediction'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preferential_attachment_prediction</th>\n",
       "      <th>jaccard_coef_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>preferential_attachment_prediction</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.762473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard_coef_prediction</th>\n",
       "      <td>0.762473</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    preferential_attachment_prediction  \\\n",
       "preferential_attachment_prediction                            1.000000   \n",
       "jaccard_coef_prediction                                       0.762473   \n",
       "\n",
       "                                    jaccard_coef_prediction  \n",
       "preferential_attachment_prediction                 0.762473  \n",
       "jaccard_coef_prediction                            1.000000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_edges[['preferential_attachment_prediction', 'jaccard_coef_prediction']].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodelist, edgelist = generate_dataframes(projected_books_graph, False, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_edges_books, books_nodelist = get_link_predictions(projected_books_graph, nodelist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = [c for c in sorted(\n",
    "    nx.connected_components(projected_members_graph), key=len, reverse=True)]\n",
    "\n",
    "preds_dfs = []\n",
    "for c in components:\n",
    "    subgraph = projected_members_graph.subgraph(c)\n",
    "    # print(len(subgraph))\n",
    "    preds = nx.common_neighbor_centrality(subgraph)\n",
    "    pred_df = pd.DataFrame(\n",
    "        list(preds), columns=['source', 'target', 'common_neighbor_centrality_prediction'])\n",
    "    preds_dfs.append(pred_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = list(nx.resource_allocation_index(projected_members_graph))\n",
    "\n",
    "\n",
    "pred_df = pd.DataFrame(preds, columns=['source', 'target', 'resource_allocation_prediction'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_edge_labels(rows):\n",
    "\n",
    "    return nodes_df[nodes_df.label == rows].label.values[0]\n",
    "pred_df['updated_target'] = pred_df.target.apply(update_edge_labels)\n",
    "pred_df['updated_source'] = pred_df.source.apply(update_edge_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = projected_members.copy()\n",
    "partial_members = partial_df.member_id.unique().tolist()\n",
    "members.loc[(members.exceptional_types.isna() == True),\n",
    "            'is_exceptional'] = False\n",
    "members.loc[(members.exceptional_types.isna() == False),\n",
    "            'is_exceptional'] = True\n",
    "members.loc[(members.member_id.isin(partial_members)), 'is_partial'] = True\n",
    "members.loc[(members.member_id.isin(partial_members)\n",
    "             == False), 'is_partial'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = all_events[all_events.start_datetime < '1925-01-01'].member_id.unique().tolist()\n",
    "books = all_events[all_events.start_datetime <'1925-01-01'].item_uri.unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = list(itertools.product(members, books))\n",
    "len(combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_df = pd.DataFrame(data=combos, columns=['source', 'target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist = pd.merge(combo_df, edges_df, on=['source', 'target'], how='outer')\n",
    "edgelist.weight.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodelist = pd.merge(members_df[['gender', 'is_organization', 'member_id', 'borrow_count', 'subscription_count', 'exceptional_types',\n",
    "            'exceptional_counts']], nodes_df, left_on='member_id', right_on='uri')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "training = edgelist[edgelist.weight > 0 ].sample(frac=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree Centrality features\n",
    "# out_degree_centrality = nx.out_degree_centrality(members_graph)\n",
    "# in_degree_centrality = nx.in_degree_centrality(members_graph)\n",
    "# # training['source_out_centrality'] = training.apply(lambda row: degree_centrality[row.source],axis=1)\n",
    "# # training['target_in_centrality'] = training.apply(lambda row: in_degree_centrality[row.target],axis=1)\n",
    "\n",
    "# # Page rank\n",
    "page_rank = nx.pagerank_scipy(members_graph)\n",
    "training['target_pagerank'] = training.apply(lambda row: page_rank[row.target],axis=1)\n",
    "\n",
    "# # Preferential Attachment\n",
    "# # For a directed graph, is equal to K_out_source * K_in_target with K the number of neighbors. Which is equivalent to multiply the available centralities.\n",
    "# training['preferencial_attachment'] = training.apply(lambda row: row.source_out_centrality * row.target_in_centrality,axis=1)\n",
    "\n",
    "# # HITS algorithm\n",
    "hub_score, authority_score = nx.hits(members_graph)\n",
    "training['source_hub_score'] = training.apply(lambda row: hub_score[row.source],axis=1)\n",
    "training['target_authority_score'] = training.apply(lambda row: authority_score[row.target],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(training.corr(),\n",
    "            vmax=0.5,\n",
    "            square=True,\n",
    "            annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.loc[training.weight > 0, 'edge_exists'] = 1\n",
    "training.loc[training.weight == 0, 'edge_exists'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(training.drop(\n",
    "    ['source', 'target', 'edge_exists'], axis=1), training.edge_exists, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF_classifer = RandomForestClassifier(n_estimators=1000)\n",
    "RF_classifer.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "#                        min_impurity_decrease=0.0,\n",
    "#                        min_samples_leaf=1, min_samples_split=2,\n",
    "#                        min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
    "#                        oob_score=False, random_state=None, verbose=0,\n",
    "#                        warm_start=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_classifer.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100,\n",
    "                           n_jobs=-1,\n",
    "                           oob_score=True,\n",
    "                           bootstrap=True,\n",
    "                           random_state=42)\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R^2 Training Score: {:.2f} \\nOOB Score: {:.2f} \\nR^2 Validation Score: {:.2f}'.format(rf.score(X_train, y_train), rf.oob_score_,rf.score(X_test, y_test)))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64bc08f1a64889c0d194e5f8836772fcdd5223ec9e3efb4bcd3e9cf106aac237"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('unknown_borrowers_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
